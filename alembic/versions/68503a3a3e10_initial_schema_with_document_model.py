"""Initial schema with Document model

Revision ID: 68503a3a3e10
Revises: 
Create Date: 2025-10-16 13:06:58.739187

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = '68503a3a3e10'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('documents',
    sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
    sa.Column('sha256_hex', sa.String(length=64), nullable=False, comment='SHA-256 hash of file (hex encoding) for deduplication'),
    sa.Column('sha256_base64', sa.String(length=44), nullable=False, comment='SHA-256 hash of file (base64 encoding) for vector store'),
    sa.Column('original_filename', sa.String(length=255), nullable=False, comment='Original PDF filename'),
    sa.Column('file_size_bytes', sa.Integer(), nullable=False, comment='File size in bytes'),
    sa.Column('page_count', sa.Integer(), nullable=True, comment='Number of pages in PDF'),
    sa.Column('doc_type', sa.String(length=100), nullable=True, comment='Document type (e.g., Invoice, Receipt, BankStatement, Contract)'),
    sa.Column('doc_subtype', sa.String(length=100), nullable=True, comment='Document subtype for granular classification'),
    sa.Column('confidence_score', sa.Float(), nullable=True, comment='Model confidence score for classification (0.0-1.0)'),
    sa.Column('issuer', sa.String(length=255), nullable=True, comment='Organization or person who issued the document'),
    sa.Column('recipient', sa.String(length=255), nullable=True, comment='Intended recipient of the document'),
    sa.Column('primary_date', sa.DateTime(), nullable=True, comment='Primary date from document (e.g., invoice date, statement date)'),
    sa.Column('secondary_date', sa.DateTime(), nullable=True, comment='Secondary date (e.g., due date, payment date)'),
    sa.Column('total_amount', sa.Float(), nullable=True, comment='Total monetary amount from document'),
    sa.Column('currency', sa.String(length=3), nullable=True, comment='Currency code (ISO 4217, e.g., USD, EUR)'),
    sa.Column('summary', sa.Text(), nullable=True, comment='Brief summary of document (â‰¤200 words)'),
    sa.Column('action_items', sa.JSON(), nullable=True, comment='Extracted action items as JSON array'),
    sa.Column('deadlines', sa.JSON(), nullable=True, comment='Important deadlines as JSON array'),
    sa.Column('urgency_level', sa.String(length=20), nullable=True, comment='Urgency assessment (low, medium, high, critical)'),
    sa.Column('tags', sa.JSON(), nullable=True, comment='User-defined or auto-generated tags as JSON array'),
    sa.Column('ocr_text_excerpt', sa.Text(), nullable=True, comment='First 500 characters of extracted text for search'),
    sa.Column('language_detected', sa.String(length=10), nullable=True, comment='Detected language code (ISO 639-1)'),
    sa.Column('vector_store_file_id', sa.String(length=255), nullable=True, comment='OpenAI vector store file ID'),
    sa.Column('vector_store_attributes', sa.JSON(), nullable=True, comment='Metadata attributes stored with vector (max 16 key-value pairs)'),
    sa.Column('processed_at', sa.DateTime(), nullable=False, comment='Timestamp when document was processed'),
    sa.Column('processing_duration_seconds', sa.Float(), nullable=True, comment='Time taken to process document (seconds)'),
    sa.Column('model_used', sa.String(length=50), nullable=False, comment='OpenAI model used for extraction (e.g., gpt-5-mini)'),
    sa.Column('prompt_tokens', sa.Integer(), nullable=True, comment='Number of input tokens used'),
    sa.Column('completion_tokens', sa.Integer(), nullable=True, comment='Number of output tokens used'),
    sa.Column('cached_tokens', sa.Integer(), nullable=True, comment='Number of cached input tokens (from prompt caching)'),
    sa.Column('total_cost_usd', sa.Float(), nullable=True, comment='Total cost for API call (USD)'),
    sa.Column('extraction_quality', sa.String(length=20), nullable=True, comment='Quality assessment (excellent, good, fair, poor)'),
    sa.Column('validation_errors', sa.JSON(), nullable=True, comment='JSON schema validation errors (if any)'),
    sa.Column('requires_review', sa.Boolean(), nullable=False, comment='Flag indicating manual review needed'),
    sa.Column('raw_response_json', sa.JSON(), nullable=True, comment='Complete API response for debugging (optional)'),
    sa.Column('created_at', sa.DateTime(), nullable=False, comment='Record creation timestamp'),
    sa.Column('updated_at', sa.DateTime(), nullable=False, comment='Record last update timestamp'),
    sa.Column('deleted_at', sa.DateTime(), nullable=True, comment='Soft delete timestamp (NULL = active record)'),
    sa.CheckConstraint('file_size_bytes > 0', name='check_file_size_positive'),
    sa.CheckConstraint('page_count > 0 OR page_count IS NULL', name='check_page_count_positive'),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_deleted_at', 'documents', ['deleted_at'], unique=False)
    op.create_index('idx_doc_type_date', 'documents', ['doc_type', 'primary_date'], unique=False)
    op.create_index('idx_issuer_date', 'documents', ['issuer', 'primary_date'], unique=False)
    op.create_index('idx_processed_at', 'documents', ['processed_at'], unique=False)
    op.create_index('idx_requires_review', 'documents', ['requires_review'], unique=False)
    op.create_index(op.f('ix_documents_doc_type'), 'documents', ['doc_type'], unique=False)
    op.create_index(op.f('ix_documents_issuer'), 'documents', ['issuer'], unique=False)
    op.create_index(op.f('ix_documents_primary_date'), 'documents', ['primary_date'], unique=False)
    op.create_index(op.f('ix_documents_processed_at'), 'documents', ['processed_at'], unique=False)
    op.create_index(op.f('ix_documents_requires_review'), 'documents', ['requires_review'], unique=False)
    op.create_index(op.f('ix_documents_sha256_base64'), 'documents', ['sha256_base64'], unique=False)
    op.create_index(op.f('ix_documents_sha256_hex'), 'documents', ['sha256_hex'], unique=True)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_documents_sha256_hex'), table_name='documents')
    op.drop_index(op.f('ix_documents_sha256_base64'), table_name='documents')
    op.drop_index(op.f('ix_documents_requires_review'), table_name='documents')
    op.drop_index(op.f('ix_documents_processed_at'), table_name='documents')
    op.drop_index(op.f('ix_documents_primary_date'), table_name='documents')
    op.drop_index(op.f('ix_documents_issuer'), table_name='documents')
    op.drop_index(op.f('ix_documents_doc_type'), table_name='documents')
    op.drop_index('idx_requires_review', table_name='documents')
    op.drop_index('idx_processed_at', table_name='documents')
    op.drop_index('idx_issuer_date', table_name='documents')
    op.drop_index('idx_doc_type_date', table_name='documents')
    op.drop_index('idx_deleted_at', table_name='documents')
    op.drop_table('documents')
    # ### end Alembic commands ###
